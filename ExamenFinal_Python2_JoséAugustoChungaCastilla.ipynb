{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ExamenFinal_Python2_JoséAugustoChungaCastilla.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.decomposition import PCA\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn.neighbors import KNeighborsClassifier as knn\n",
        "from sklearn.metrics import recall_score, precision_score\n",
        "from sklearn.ensemble import RandomForestRegressor as RFR\n",
        "from sklearn.model_selection import train_test_split as tts"
      ],
      "metadata": {
        "id": "eekvgbRCwBPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "W7RBsObSiHCc",
        "outputId": "5823c6c5-a087-4b2e-9997-3a073135b396"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nEstablezca 2 modelos de clasificación para el data Iris\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "\"\"\"\n",
        "Establezca 2 modelos de clasificación para el data Iris\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primer Modelo - Implementando el método KNN"
      ],
      "metadata": {
        "id": "mNvSnHEbwOw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfiris = datasets.load_iris()\n",
        "X = dfiris.data\n",
        "y = dfiris.target\n",
        "y = np.reshape(y,(150,1))\n",
        "\n",
        "# Dividimos la data\n",
        "Xtrain, Xtest, ytrain, ytest = tts(X,y,test_size = 0.30, random_state = 42)\n",
        "\n",
        "###Entrenamiento de la data (AJUSTE)\n",
        "#Crear el modelo\n",
        "modeloKNN = knn(n_neighbors = 3)\n",
        "modeloKNN.fit(Xtrain,ytrain)\n",
        "\n",
        "#Hacer una prediccion de los valores de prueba\n",
        "ypredi1 = modeloKNN.predict(Xtest)\n",
        "ypredtrain = modeloKNN.predict(Xtrain) \n",
        "\n",
        "#score_total\n",
        "score_totaltrain = modeloKNN.score(Xtrain,ytrain)\n",
        "recallscoretrain = recall_score(ytrain,ypredtrain,average='micro')\n",
        "precisionscoretrain = precision_score(ytrain,ypredtrain,average='micro')\n",
        "\n",
        "print(\"El score en entrenamiento es \", score_totaltrain)\n",
        "print(\"El recall en recallscoretrain es\", recallscoretrain)\n",
        "print(\"La precision en entrenamiento es\", precisionscoretrain)\n",
        "\n",
        "print('-'*50)\n",
        "print('-'*50)\n",
        "\n",
        "score_totalvalidation = modeloKNN.score(Xtest,ytest)\n",
        "recallscorevalidation = recall_score(ytest,ypredi1,average='micro')\n",
        "precisionscorevalidation = precision_score(ytest,ypredi1,average='micro')\n",
        "\n",
        "print(\"El score en validacion es \", score_totalvalidation)\n",
        "print(\"El recall en validacion es\", recallscorevalidation)\n",
        "print(\"La precision en validacion es\", precisionscorevalidation)\n"
      ],
      "metadata": {
        "id": "gs9-AaEPwKzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Segundo Modelo - Implementando un Regresor Logistico"
      ],
      "metadata": {
        "id": "YMvzK10k0MM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfiris = datasets.load_iris()\n",
        "X = dfiris.data\n",
        "y = dfiris.target\n",
        "y = np.reshape(y,(150,1))\n",
        "\n",
        "Xtrain,Xtest,ytrain,ytest = tts(X,y,test_size = 0.20, random_state = 32)\n",
        "modellogist = LogisticRegression(max_iter=150)\n",
        "modellogist.fit(Xtrain,ytrain)\n",
        "####\n",
        "ypredtest = modellogist.predict(Xtest)\n",
        "ypredtrain = modellogist.predict(Xtrain)\n",
        "###\n",
        "score_totalentrenamiento = modellogist.score(Xtrain,ytrain)\n",
        "recallscoreentrenamiento = recall_score(ytrain,ypredtrain,average='micro')\n",
        "precisionentrenamiento = precision_score(ytrain,ypredtrain,average='micro')\n",
        "print(\"score_total de entrenamiento: \",round(score_totalentrenamiento,2))\n",
        "print(\"recallscore de entrenamiento: \",round(recallscoreentrenamiento,2))\n",
        "print(\"precision de entrenamiento: \",round(precisionentrenamiento,2))\n",
        "\n",
        "print('-'*50)\n",
        "print('-'*50)\n",
        "\n",
        "score_total = modellogist.score(Xtest,ytest)\n",
        "recallscore = recall_score(ytest,ypredtest,average='micro')\n",
        "precision = precision_score(ytest,ypredtest,average='micro')\n",
        "print(\"score_total: \",round(score_total,2))\n",
        "print(\"recallscore: \",round(recallscore,2))\n",
        "print(\"precision: \",round(precision,2))"
      ],
      "metadata": {
        "id": "KDUM1Hc10Nmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Evalúa 2 modelos: Uno con PCA y otro sin PCA para el modelo de clasificación del dataset melbournhouses\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wCaT3PQMimn6",
        "outputId": "74c873e5-424a-459e-d02f-31b2f4b5d5c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nEvalúa 2 modelos: Uno con PCA y otro sin PCA para el modelo de clasificación del dataset melbournhouses\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primer Modelo con PCA"
      ],
      "metadata": {
        "id": "eOZ14TDJFFsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfmelhou = pd.read_csv('https://raw.githubusercontent.com/pedrorotta/PythonIntermedio2022/main/Examen/melbournehouses.csv')\n",
        "print(dfmelhou.head())\n",
        "print(\"-\"*75)\n",
        "print(\"-\"*75)\n",
        "X = np.array(dfmelhou.drop(columns = ['Suburb','Address','Type','Method','SellerG','Date','Car','BuildingArea','YearBuilt','CouncilArea','Regionname']))\n",
        "print(\"Todos los valores de la primera fila\")\n",
        "print(X[0,:])\n",
        "print(\"-\"*75)\n",
        "print(\"-\"*75)\n",
        "#Escalamiento\n",
        "escalador = MinMaxScaler()\n",
        "X_escalado = escalador.fit_transform(X)\n",
        "print(\"Visualizacion del x escalado en la primera fila\")\n",
        "print(X_escalado[0,:])\n",
        "\n",
        "###### Aplicando PCA ###### \n",
        "#Hacer el análisis de los componentes principales\n",
        "pca1 = PCA(n_components=2) # Reducción dimensional a 2 dimensiones\n",
        "#Generar el valor de la matriz de autovectores\n",
        "pca1.fit(X_escalado)\n",
        "Xpca = pca1.transform(X_escalado)\n",
        "print(\"-\"*75)\n",
        "print(\"-\"*75)\n",
        "#print(np.shape(pca1.components_))\n",
        "\n",
        "### Diferenciar entre X_escalado y Xpca\n",
        "print(\"Diferencia entre X_escalado y Xpca: \")\n",
        "print(X_escalado[0,:])\n",
        "print(\"-\"*75)\n",
        "print(Xpca[0,:])\n",
        "\n",
        "### Podemos hacer un gráfico de dispersión de clases\n",
        "#print(np.shape(Xpca))\n",
        "#Definimos el y\n",
        "y = np.array(dfmelhou['Price'])\n",
        "#print(np.shape(y))\n",
        "\n",
        "print(\"=\"*75)\n",
        "print(\"=\"*75)\n",
        "\n",
        "print(\"Gráfico de dispersión mediante Matplotlib:\")\n",
        "plt.figure(figsize = (30,25))\n",
        "plt.scatter(Xpca[:,0],Xpca[:,1],c= y, s = 30)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dUi2OJrLFFSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Segundo Modelo sin PCA implementando un Regresor Logistico"
      ],
      "metadata": {
        "id": "HyK7Gf3MSuzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfmelhou = pd.read_csv('https://raw.githubusercontent.com/pedrorotta/PythonIntermedio2022/main/Examen/melbournehouses.csv')\n",
        "print(dfmelhou.head())\n",
        "\n",
        "X = np.array(dfmelhou.drop(columns = ['Suburb','Address','Type','Method','SellerG','Date','Car','BuildingArea','YearBuilt','CouncilArea','Regionname']))\n",
        "y = np.array(dfmelhou['Rooms'])\n",
        "y = np.reshape(y,(13580,1))\n",
        "\n",
        "Xtrain,Xtest,ytrain,ytest = tts(X,y,test_size = 0.20, random_state = 32)\n",
        "modellogist = LogisticRegression(max_iter=300)\n",
        "modellogist.fit(Xtrain,ytrain)\n",
        "####\n",
        "ypredtest = modellogist.predict(Xtest)\n",
        "ypredtrain = modellogist.predict(Xtrain)\n",
        "###\n",
        "score_totalentrenamiento = modellogist.score(Xtrain,ytrain)\n",
        "recallscoreentrenamiento = recall_score(ytrain,ypredtrain,average='micro')\n",
        "precisionentrenamiento = precision_score(ytrain,ypredtrain,average='micro')\n",
        "print(\"score_total de entrenamiento: \",round(score_totalentrenamiento,2))\n",
        "print(\"recallscore de entrenamiento: \",round(recallscoreentrenamiento,2))\n",
        "print(\"precision de entrenamiento: \",round(precisionentrenamiento,2))\n",
        "\n",
        "print('-'*50)\n",
        "print('-'*50)\n",
        "\n",
        "score_total = modellogist.score(Xtest,ytest)\n",
        "recallscore = recall_score(ytest,ypredtest,average='micro')\n",
        "precision = precision_score(ytest,ypredtest,average='micro')\n",
        "print(\"score_total: \",round(score_total,2))\n",
        "print(\"recallscore: \",round(recallscore,2))\n",
        "print(\"precision: \",round(precision,2))"
      ],
      "metadata": {
        "id": "10Erb7eRSx0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "¿Existe sobreajuste al aplicar un modelo de RF con n = 200 para el modelo de wine.csv? \n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "s_3ODXOsinzB",
        "outputId": "cf5dc440-565b-4d87-e30c-b3eb2f41dd03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n¿Existe sobreajuste al aplicar un modelo de RF con n = 200 para el modelo de wine.csv? \\n'"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_wine = pd.read_excel('/content/wine.xlsx')\n",
        "print(df_wine.head())\n",
        "print(\"-\"*75)\n",
        "print(\"-\"*75)\n",
        "\n",
        "#Paso Nro 1: Obtener la matriz de características. \n",
        "X_featuresdf = df_wine.drop(columns = ['description'])\n",
        "X_featuresarray = np.array(X_featuresdf)\n",
        "### Encoding => Variables de texto\n",
        "X_feat_country = X_featuresdf['country']\n",
        "X_feat_country_array = np.array(X_feat_country)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "Encoder = LabelEncoder()\n",
        "Encoder.fit(X_feat_country_array)\n",
        "x_gen_encoder = Encoder.fit_transform(X_feat_country_array)\n",
        "#print(x_gen_encoder)\n",
        "## Eliminar el X_gen e ingresamos el xgencodificado\n",
        "X_singen = X_featuresdf.drop(columns = ['country'])\n",
        "X_singen['CountryEscalado'] = x_gen_encoder\n",
        "print(X_singen.head())\n",
        "print(\"-\"*75)\n",
        "print(\"-\"*75)\n",
        "\n",
        "countryescalado_array = np.array(X_singen['CountryEscalado'])\n",
        "X = np.c_[countryescalado_array]\n",
        "y = np.array(df_wine['points'])\n",
        "#print(np.shape(X))\n",
        "y = np.reshape(y,(150930,1))\n",
        "#print(np.shape(y))\n",
        "Xtrain,Xtest,ytrain,ytest = tts(X,y,random_state = 42, test_size = 0.25) #dividimos la data\n",
        "modeloRF = RFR(random_state= 42)\n",
        "modeloRF.fit(Xtrain,ytrain) #Entrenamos el modelo\n",
        "### Verificamos los resultados\n",
        "ypred = modeloRF.predict(Xtest)\n",
        "r2RF = r2_score(ytest,ypred)\n",
        "print(\"Validacion: \",r2RF)\n",
        "### Cómo evalúo si existe subajuste o sobreajuste\n",
        "#Comparar los resultados de entrenamiento y los de prueba\n",
        "ypred_train = modeloRF.predict(Xtrain)\n",
        "r2RT = r2_score(ytrain,ypred_train)\n",
        "print(\"Entrenamiento: \",r2RT)\n",
        "print(\"No existe sobreajuste\")"
      ],
      "metadata": {
        "id": "SqdRxQ3H4C-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Puedes graficar un modelo de deep learning para la dataset de breast-cancer\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "RWeTxXv9ipBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfbreast = pd.read_csv('https://raw.githubusercontent.com/pedrorotta/PythonIntermedio2022/main/clase6/breast-cancer.csv')\n",
        "dfX = dfbreast.drop(columns = ['id','diagnosis'])\n",
        "y = np.array(dfbreast['diagnosis'])\n",
        "Encoder = LabelEncoder()\n",
        "y = Encoder.fit_transform(y)\n",
        "y = np.reshape(y,(len(y),1))\n",
        "#print(y[:4])\n",
        "#print(np.shape(y))\n",
        "escalar = MinMaxScaler()\n",
        "X = np.array(dfX)\n",
        "X = escalar.fit_transform(X)\n",
        "#print(X[0:4,:])\n",
        "Xtrain,Xtest,ytrain,ytest = tts(X,y)\n",
        "\n",
        "## Crear el modelo\n",
        "ModeloClasificador = tf.keras.Sequential([\n",
        "      tf.keras.Input(shape = (30,)),\n",
        "      tf.keras.layers.Dense(100,activation = 'relu'),\n",
        "      tf.keras.layers.Dense(50,activation = 'relu'),\n",
        "      tf.keras.layers.Dense(30,activation = 'relu'),\n",
        "      tf.keras.layers.Dense(10,activation = 'relu'),\n",
        "      tf.keras.layers.Dense(1,activation = 'sigmoid')\n",
        "])\n",
        "ModeloClasificador.compile(loss = tf.keras.losses.binary_crossentropy,optimizer = tf.keras.optimizers.SGD(),\n",
        "                           metrics = 'accuracy')\n",
        "ModeloClasificador.fit(Xtrain,ytrain,epochs = 400)\n",
        "\n",
        "print('-'*150)\n",
        "print('-'*150)\n",
        "\n",
        "ypred_train = np.round(ModeloClasificador.predict(Xtrain),0)\n",
        "ypred_test = np.round(ModeloClasificador.predict(Xtest),0)\n",
        "#print(ypred_train[0:4])\n",
        "recall_clasificadortest = recall_score(ytest,ypred_test)\n",
        "recall_clasificadort = recall_score(ytrain,ypred_train)\n",
        "print(\"El recall en entrenamiento es: \", recall_clasificadort)\n",
        "print(\"El recall en validación es: \", recall_clasificadortest)\n",
        "\n",
        "print('-'*150)\n",
        "print('-'*150)\n",
        "\n",
        "#Describo la gráfica del modelo anterior\n",
        "ModeloClasificador.build()\n",
        "ModeloClasificador.summary()\n",
        "\n",
        "print('-'*150)\n",
        "print('-'*150)\n",
        "\n",
        "#Para la visualización gráfica\n",
        "plot_model(model = ModeloClasificador,show_shapes = True)"
      ],
      "metadata": {
        "id": "uD7Xe5k2RMCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Crea una función que aplane la ruta de una imágen\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "pO3XgNKyip8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creación de función que aplane la ruta de una imágen\n",
        "def Funcionflatten(L):\n",
        "  vector = []\n",
        "  for image in L:\n",
        "    for item in image:\n",
        "      vector.append(item)\n",
        "      result = vector\n",
        "  return result\n",
        "\n",
        "###Creamos una lista de imagenes\n",
        "#images = [img1,img2,img3]\n",
        "images = [[1,5,11],[2,3,8],[10,52,21]]\n",
        "#Probando la función\n",
        "print(Funcionflatten(images))"
      ],
      "metadata": {
        "id": "ANaj2GnroIcX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}